{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_chat_to_jsonl(chat_file, output_file, query_name, response_name):\n",
    "    with open(chat_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    conversations = []\n",
    "    current_query = None\n",
    "    current_response = None\n",
    "\n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        # Extract date, time, sender, and message\n",
    "        if '] ' in line and ': ' in line:\n",
    "            try:\n",
    "                timestamp, content = line.split('] ', 1)\n",
    "                sender, message = content.split(': ', 1)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            sender = sender.strip()\n",
    "            message = message.strip()\n",
    "\n",
    "            # Handle query-response mapping\n",
    "            if sender == query_name:\n",
    "                if current_query and current_response:\n",
    "                    conversations.append({\"query\": current_query, \"response\": current_response})\n",
    "                current_query = message\n",
    "                current_response = None  # Reset the response\n",
    "            elif sender == response_name:\n",
    "                if current_query:  # Ensure there's a query before adding a response\n",
    "                    if current_response:\n",
    "                        current_response += \" \" + message\n",
    "                    else:\n",
    "                        current_response = message\n",
    "        else:\n",
    "            # Continuation of the message\n",
    "            if current_response is not None:\n",
    "                current_response += \" \" + line.strip()\n",
    "\n",
    "    # Append the last conversation\n",
    "    if current_query and current_response:\n",
    "        conversations.append({\"query\": current_query, \"response\": current_response})\n",
    "\n",
    "    # Write to JSONL\n",
    "    with open(output_file, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for convo in conversations:\n",
    "            jsonl_file.write(json.dumps(convo, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. JSONL file saved as chat_data.jsonl.\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "chat_file = '_chat.txt'\n",
    "output_file = 'chat_data.jsonl'\n",
    "query_name = 'Recpient Name'\n",
    "response_name = 'Your Name'\n",
    "\n",
    "# Convert chat to JSONL\n",
    "parse_chat_to_jsonl(chat_file, output_file, query_name, response_name)\n",
    "\n",
    "print(f\"Conversion complete. JSONL file saved as {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. The formatted data is saved to formatted_chat_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to filter out unwanted responses\n",
    "def is_valid_response(response):\n",
    "    # Check if response contains any unwanted phrases\n",
    "    return not any(phrase in response.lower() for phrase in [\"sticker omitted\", \"image omitted\", \"you deleted this message\"])\n",
    "\n",
    "# Function to convert your chat_data.jsonl to the desired format\n",
    "def convert_chat_data(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            chat = json.loads(line.strip())\n",
    "            query = chat[\"query\"]\n",
    "            response = chat[\"response\"]\n",
    "            \n",
    "            # Filter out invalid responses\n",
    "            if is_valid_response(response):\n",
    "                # Create the conversation in the required format\n",
    "                conversation = [\n",
    "                    {\"from\": \"human\", \"value\": query},\n",
    "                    {\"from\": \"gpt\", \"value\": response}\n",
    "                ]\n",
    "                # Write the conversation to the output file\n",
    "                json.dump(conversation, outfile, ensure_ascii=False)\n",
    "                outfile.write(\"\\n\")  # Add a newline for each conversation\n",
    "\n",
    "# File paths\n",
    "input_file = 'chat_data.jsonl'  # Input file containing the original data\n",
    "output_file = 'formatted_chat_data.jsonl'  # Output file for the formatted data\n",
    "\n",
    "# Convert the data\n",
    "convert_chat_data(input_file, output_file)\n",
    "\n",
    "print(\"Conversion complete. The formatted data is saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def transform_chat_data(input_file, output_file):\n",
    "    # Initialize list to store conversation blocks\n",
    "    current_block = []\n",
    "    \n",
    "    # Words to filter out\n",
    "    filter_words = [\"image omitted\", \"sticker omitted\", \"You deleted this message\"]\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        # Read line by line\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Parse JSON from each line\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Skip responses containing filter words\n",
    "                if any(word in data['response'].lower() for word in filter_words):\n",
    "                    continue\n",
    "                \n",
    "                # Add to current block\n",
    "                current_block.extend([\n",
    "                    {\"from\": \"human\", \"value\": data[\"query\"]},\n",
    "                    {\"from\": \"gpt\", \"value\": data[\"response\"]}\n",
    "                ])\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON line: {line}\")\n",
    "                continue\n",
    "    \n",
    "    # Write transformed data\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump([current_block], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Usage\n",
    "transform_chat_data('chat_data.jsonl', 'transformed_chat.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
